{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a6r2nVXtY5vl",
        "outputId": "1d86f8c3-909e-459b-b6f8-1d928076eb97"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.8.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.10/dist-packages (0.13.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.5.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.55.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (11.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.2.0)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "# Ensure all necessary libraries are installed\n",
        "!pip install pandas numpy matplotlib seaborn scikit-learn\n",
        "\n",
        "# Import essential libraries for data manipulation and visualization\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import os\n",
        "os.makedirs('data', exist_ok=True)\n",
        "\n",
        "\n",
        "# Import machine learning modules\n",
        "#from sklearn.model_selection import train_test_split, cross_val_score\n",
        "#from sklearn.linear_model import LinearRegression\n",
        "#from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
        "#from sklearn.metrics import mean_squared_error, mean_absolute_error"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the zip file from GitHub\n",
        "!wget -O car_price_data.zip \"https://github.com/SripathiVR/Car_Price_Prediction/blob/main/Car_Price%20Prediction.zip?raw=true\"\n",
        "\n",
        "# Unzip the downloaded file\n",
        "!unzip car_price_data.zip -d ./car_price_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vBBRh3pcZm_3",
        "outputId": "4fab896a-d3ed-4a73-add3-943ebc98998d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-11-28 12:47:15--  https://github.com/SripathiVR/Car_Price_Prediction/blob/main/Car_Price%20Prediction.zip?raw=true\n",
            "Resolving github.com (github.com)... 140.82.121.3\n",
            "Connecting to github.com (github.com)|140.82.121.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://github.com/SripathiVR/CarDekho-Insights-Predicting-Used-Car-Prices-with-Streamlit-and-ML/blob/main/Car_Price%20Prediction.zip?raw=true [following]\n",
            "--2024-11-28 12:47:15--  https://github.com/SripathiVR/CarDekho-Insights-Predicting-Used-Car-Prices-with-Streamlit-and-ML/blob/main/Car_Price%20Prediction.zip?raw=true\n",
            "Reusing existing connection to github.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://github.com/SripathiVR/CarDekho-Insights-Predicting-Used-Car-Prices-with-Streamlit-and-ML/raw/refs/heads/main/Car_Price%20Prediction.zip [following]\n",
            "--2024-11-28 12:47:15--  https://github.com/SripathiVR/CarDekho-Insights-Predicting-Used-Car-Prices-with-Streamlit-and-ML/raw/refs/heads/main/Car_Price%20Prediction.zip\n",
            "Reusing existing connection to github.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/SripathiVR/CarDekho-Insights-Predicting-Used-Car-Prices-with-Streamlit-and-ML/refs/heads/main/Car_Price%20Prediction.zip [following]\n",
            "--2024-11-28 12:47:15--  https://raw.githubusercontent.com/SripathiVR/CarDekho-Insights-Predicting-Used-Car-Prices-with-Streamlit-and-ML/refs/heads/main/Car_Price%20Prediction.zip\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.109.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10799915 (10M) [application/zip]\n",
            "Saving to: ‘car_price_data.zip’\n",
            "\n",
            "car_price_data.zip  100%[===================>]  10.30M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2024-11-28 12:47:18 (90.9 MB/s) - ‘car_price_data.zip’ saved [10799915/10799915]\n",
            "\n",
            "Archive:  car_price_data.zip\n",
            "   creating: ./car_price_data/Car_Price Prediction/\n",
            "   creating: ./car_price_data/Car_Price Prediction/Car_Dataset/\n",
            "  inflating: ./car_price_data/Car_Price Prediction/Car_Dataset/bangalore_cars.xlsx  \n",
            "  inflating: ./car_price_data/Car_Price Prediction/Car_Dataset/chennai_cars.xlsx  \n",
            "  inflating: ./car_price_data/Car_Price Prediction/Car_Dataset/delhi_cars.xlsx  \n",
            "  inflating: ./car_price_data/Car_Price Prediction/Car_Dataset/hyderabad_cars.xlsx  \n",
            "  inflating: ./car_price_data/Car_Price Prediction/Car_Dataset/jaipur_cars.xlsx  \n",
            "  inflating: ./car_price_data/Car_Price Prediction/Car_Dataset/kolkata_cars.xlsx  \n",
            "  inflating: ./car_price_data/Car_Price Prediction/Car_Dekho-Used_Car_Price_Prediction.pdf  \n",
            "  inflating: ./car_price_data/Car_Price Prediction/Car_Dekho.ipynb  \n",
            "  inflating: ./car_price_data/Car_Price Prediction/car_dekho_app.py  \n",
            "  inflating: ./car_price_data/Car_Price Prediction/car_dekho_cleaned_dataset.csv  \n",
            "  inflating: ./car_price_data/Car_Price Prediction/car_dekho_cleaned_dataset_Raw.csv  \n",
            "  inflating: ./car_price_data/Car_Price Prediction/car_dekho_Structured.csv  \n",
            "  inflating: ./car_price_data/Car_Price Prediction/Feature Description.docx  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import requests\n",
        "import io\n",
        "\n",
        "# Step 1: Download the zip file from GitHub\n",
        "url = 'https://github.com/SripathiVR/Car_Price_Prediction/raw/main/Car_Price%20Prediction.zip'\n",
        "response = requests.get(url)\n",
        "zip_file = zipfile.ZipFile(io.BytesIO(response.content))\n",
        "\n",
        "# Step 2: Check the contents of the zip file\n",
        "print(\"Files in zip:\", zip_file.namelist())  # List all files in the zip\n",
        "\n",
        "\n",
        "# Step 3: Load the CSV file (replace with actual CSV name if different)\n",
        "\n",
        "try:\n",
        "    # Adjust the file path to the specific CSV inside the zip structure\n",
        "    data = pd.read_csv(zip_file.open('Car_Price Prediction/car_dekho_cleaned_dataset_Raw.csv'))\n",
        "    print(data.head())\n",
        "except KeyError:\n",
        "    print(\"Specified file was not found in the zip archive.\")\n",
        "except pd.errors.EmptyDataError:\n",
        "    print(\"The file appears to be empty.\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-uMsZO7SZ9US",
        "outputId": "f4d91ff6-d5f2-4dd4-9aa3-6b5904997fcf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files in zip: ['Car_Price Prediction/', 'Car_Price Prediction/Car_Dataset/', 'Car_Price Prediction/Car_Dataset/bangalore_cars.xlsx', 'Car_Price Prediction/Car_Dataset/chennai_cars.xlsx', 'Car_Price Prediction/Car_Dataset/delhi_cars.xlsx', 'Car_Price Prediction/Car_Dataset/hyderabad_cars.xlsx', 'Car_Price Prediction/Car_Dataset/jaipur_cars.xlsx', 'Car_Price Prediction/Car_Dataset/kolkata_cars.xlsx', 'Car_Price Prediction/Car_Dekho-Used_Car_Price_Prediction.pdf', 'Car_Price Prediction/Car_Dekho.ipynb', 'Car_Price Prediction/car_dekho_app.py', 'Car_Price Prediction/car_dekho_cleaned_dataset.csv', 'Car_Price Prediction/car_dekho_cleaned_dataset_Raw.csv', 'Car_Price Prediction/car_dekho_Structured.csv', 'Car_Price Prediction/Feature Description.docx']\n",
            "   it      ft         bt        km transmission  ownerNo      oem  \\\n",
            "0   0  Petrol  Hatchback  120000.0       Manual        3   Maruti   \n",
            "1   0  Petrol        SUV   32706.0       Manual        2     Ford   \n",
            "2   0  Petrol  Hatchback   11949.0       Manual        1     Tata   \n",
            "3   0  Petrol      Sedan   17794.0       Manual        1  Hyundai   \n",
            "4   0  Diesel        SUV   60000.0       Manual        1   Maruti   \n",
            "\n",
            "                model  modelYear  centralVariantId  ... data_2_list_10_key  \\\n",
            "0      Maruti Celerio       2015              3979  ...    No Door Numbers   \n",
            "1       Ford Ecosport       2018              6087  ...       Cargo Volumn   \n",
            "2          Tata Tiago       2018              2983  ...   Alloy Wheel Size   \n",
            "3       Hyundai Xcent       2014              1867  ...   Alloy Wheel Size   \n",
            "4  Maruti SX4 S Cross       2015              4277  ...   Alloy Wheel Size   \n",
            "\n",
            "   data_2_list_10_value.1 data_2_list_11_key data_2_list_11_value.1  \\\n",
            "0                       5       Cargo Volumn             235-litres   \n",
            "1              352-litres                NaN                    NaN   \n",
            "2                      14    No Door Numbers                      5   \n",
            "3                      14    No Door Numbers                      4   \n",
            "4                      16    No Door Numbers                      5   \n",
            "\n",
            "  top_5_key.1 top_5_value.2  \\\n",
            "0         NaN           NaN   \n",
            "1       Seats           5.0   \n",
            "2       Seats           5.0   \n",
            "3       Seats           5.0   \n",
            "4       Seats           5.0   \n",
            "\n",
            "                                           car_links       City mileage Seats  \n",
            "0  https://www.cardekho.com/used-car-details/used...  Bangalore   23.10   5.0  \n",
            "1  https://www.cardekho.com/buy-used-car-details/...  Bangalore   17.00   5.0  \n",
            "2  https://www.cardekho.com/used-car-details/used...  Bangalore   23.84   5.0  \n",
            "3  https://www.cardekho.com/buy-used-car-details/...  Bangalore   19.10   5.0  \n",
            "4  https://www.cardekho.com/used-car-details/used...  Bangalore   23.65   5.0  \n",
            "\n",
            "[5 rows x 214 columns]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-36e756fa3ab9>:18: DtypeWarning: Columns (155) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  data = pd.read_csv(zip_file.open('Car_Price Prediction/car_dekho_cleaned_dataset_Raw.csv'))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Step 1: Remove Columns with Excessive Missing Values\n",
        "missing_threshold = len(data) * 0.3\n",
        "cleaned_data = data.dropna(thresh=missing_threshold, axis=1)\n",
        "\n",
        "# Step 2: Fill in Missing Data\n",
        "for feature in cleaned_data.columns:\n",
        "    # Determine if the column is categorical\n",
        "    if cleaned_data[feature].dtype == 'object':\n",
        "        # Replace missing values with the mode (most common value)\n",
        "        most_common_value = cleaned_data[feature].mode()[0]\n",
        "        cleaned_data[feature].fillna(most_common_value, inplace=True)\n",
        "    else:\n",
        "        # Replace missing values with the mean of the column\n",
        "        mean_value = cleaned_data[feature].mean()\n",
        "        cleaned_data[feature].fillna(mean_value, inplace=True)\n",
        "\n",
        "# Step 3: Eliminate Non-Essential Columns\n",
        "unnecessary_columns = ['car_links', 'City']  # Update this list as required\n",
        "cleaned_data = cleaned_data.drop(columns=unnecessary_columns, errors='ignore')\n",
        "\n",
        "# Step 4: Transform Categorical Features\n",
        "# Apply Label Encoding to columns with high cardinality\n",
        "high_cardinality_features = [feature for feature in cleaned_data.select_dtypes(include=['object']).columns if cleaned_data[feature].nunique() > 100]\n",
        "for feature in high_cardinality_features:\n",
        "    label_encoder = LabelEncoder()\n",
        "    cleaned_data[feature] = label_encoder.fit_transform(cleaned_data[feature].astype(str))\n",
        "\n",
        "# One-Hot Encode low-cardinality categorical features\n",
        "low_cardinality_features = [feature for feature in cleaned_data.select_dtypes(include=['object']).columns if feature not in high_cardinality_features]\n",
        "cleaned_data = pd.get_dummies(cleaned_data, drop_first=True, columns=low_cardinality_features)\n",
        "\n",
        "# Display the structure of the cleaned dataset\n",
        "print(\"\\nSummary of Cleaned Data:\")\n",
        "cleaned_data.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VErqtGU2aIRo",
        "outputId": "282c3062-ccdc-46af-8ad3-377c4b631c00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-b46304e204ee>:17: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  cleaned_data[feature].fillna(mean_value, inplace=True)\n",
            "<ipython-input-4-b46304e204ee>:13: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  cleaned_data[feature].fillna(most_common_value, inplace=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Summary of Cleaned Data:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 7511 entries, 0 to 7510\n",
            "Columns: 2023 entries, it to data_2_list_11_key_No Door Numbers\n",
            "dtypes: bool(1982), float64(6), int64(35)\n",
            "memory usage: 16.5 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import zscore\n",
        "\n",
        "# Step 5: Check for remaining missing values\n",
        "print(\"Remaining Missing Values:\\n\", cleaned_data.isnull().sum()[cleaned_data.isnull().sum() > 0])\n",
        "\n",
        "# Summary of data types\n",
        "print(\"\\nData Types Summary:\\n\", cleaned_data.dtypes.value_counts())\n",
        "\n",
        "# Outliers analysis for numeric columns\n",
        "outliers = {}\n",
        "for col in cleaned_data.select_dtypes(include=['float64', 'int64']).columns:\n",
        "    outliers[col] = (zscore(cleaned_data[col].fillna(0)) > 3).sum()  # Count of outliers\n",
        "print(\"\\nOutliers Count in Numerical Columns:\\n\", outliers)\n",
        "\n",
        "# Detect columns with single unique values (likely redundant)\n",
        "try:\n",
        "    redundant_columns = [col for col in cleaned_data.columns if cleaned_data[col].nunique(dropna=False) == 1]\n",
        "    print(\"\\nRedundant Columns (Single Unique Value):\\n\", redundant_columns)\n",
        "\n",
        "    # Optionally, drop redundant columns\n",
        "    cleaned_data = cleaned_data.drop(columns=redundant_columns)\n",
        "    print(\"\\nRedundant columns removed. Final Data Shape:\", cleaned_data.shape)\n",
        "\n",
        "except Exception as e:\n",
        "    print(\"An error occurred:\", e)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PwIMHqxUaP4G",
        "outputId": "9e0e9154-624b-4e82-e175-a7fb854d56be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Remaining Missing Values:\n",
            " Series([], dtype: int64)\n",
            "\n",
            "Data Types Summary:\n",
            " bool       1982\n",
            "int64        35\n",
            "float64       6\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Outliers Count in Numerical Columns:\n",
            " {'it': 0, 'km': 14, 'ownerNo': 97, 'model': 0, 'modelYear': 0, 'centralVariantId': 0, 'variantName': 0, 'price': 55, 'top_0_value': 0, 'top_4_value': 0, 'top_5_value': 0, 'top_6_value': 0, 'top_7_value': 0, 'top_9_value': 0, 'top_1_value.2': 0, 'top_2_value.2': 0, 'top_3_value.2': 0, 'data_0_list_0_value.1': 0, 'data_0_list_1_value.1': 0, 'data_0_list_2_value.1': 0, 'data_0_list_3_value.1': 0, 'data_0_list_4_value.1': 0, 'data_0_list_8_value.1': 0, 'data_0_list_9_value.1': 0, 'data_1_list_0_value.1': 25, 'data_1_list_1_value.1': 52, 'data_1_list_2_value.1': 0, 'data_1_list_3_value.1': 29, 'data_1_list_4_value.1': 0, 'data_1_list_5_value.1': 0, 'data_1_list_6_value.1': 0, 'data_2_list_4_value.1': 0, 'data_2_list_6_value.1': 0, 'data_2_list_7_value.1': 0, 'data_2_list_8_value.1': 0, 'data_2_list_9_value.1': 0, 'data_2_list_10_value.1': 0, 'data_2_list_11_value.1': 0, 'top_5_value.2': 337, 'mileage': 46, 'Seats': 600}\n",
            "An error occurred: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "save_path = '/content/data/cleaned_data.csv'\n",
        "cleaned_data.to_csv(save_path, index=False)\n",
        "# Make sure to create the data directory first\n",
        "\n",
        "os.makedirs('data', exist_ok=True)\n",
        "\n",
        "# Save the cleaned data\n",
        "cleaned_data.to_csv('data/cleaned_data.csv', index=False)\n",
        "\n",
        "# Verify if the file is saved correctly\n",
        "if os.path.exists('data/cleaned_data.csv'):\n",
        "       print(f\"Data saved successfully to {save_path}\")\n",
        "else:\n",
        "    print(\"Error: Data file was not saved.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2IMtS1a1aWQ7",
        "outputId": "6e6843fb-1ade-4a0b-f656-cde3ead31c30"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data saved successfully to /content/data/cleaned_data.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Files in '/content/data' directory:\", os.listdir('/content/data'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HtIOSYeZac66",
        "outputId": "3cc18e35-9a37-42dd-f5a0-9bd5f44fee8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files in '/content/data' directory: ['cleaned_data.csv']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cleaned_data.to_csv('/content/data/cleaned_data.csv', index=False)"
      ],
      "metadata": {
        "id": "wnr5qynbaiLf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}